{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/featuretools.png)\n",
    "\n",
    "# Predicting Loan Repayment with Automated Feature Engineering in Featuretools\n",
    "\n",
    "Feature engineering is the process of creating new features (also called predictors or explanatory variables) out of an existing dataset. Traditionally, this process is done by hand using domain knowledge to build new features one at a time. Feature engineering is crucial for a data science problem and a manual approach is time-consuming, tedious, error-prone, and must be re-done for each problem. Automated feature engineering aims to aid the data scientist in this critical process by automatically creating hundreds or thousands of new features from a set of related tables in a fraction of the time as the manual approach. In this notebook, we will apply automated feature engineering to the Home Credit Default Risk loan dataset using [Featuretools, an open-source Python library](https://www.featuretools.com/) for automated feature engineering. \n",
    "\n",
    "This problem is a machine learning competition on Kaggle where the objective is to predict if an applicant will default on a loan given comprehensive data on past loans and applicants. The data is spread across seven different tables making this an ideal problem for automated feature engineering: all of the data must be gathered into a single dataframe for training (and one for testing) with the aim of capturing as much usable information for the prediction problem as possible. As we will see, featuretools can efficiently carry out the tedious process of using all of these tables to make new features with only a few lines of code. Moreover, this code is generally applicable to any data science problem! \n",
    "\n",
    "The general idea of automated feature engineering is picture below:\n",
    "\n",
    "![](../../images/AutomatedFeatureEngineering.png)\n",
    "\n",
    "\n",
    "## Approach \n",
    "\n",
    "In this notebook, we will implement an automated feature engineering approach to the loan repayment problem. While Featuretools allows plenty of options for customization of the library to improve accuracy, we'll focus on a fairly high-level implementation.\n",
    "\n",
    "Our approach will be as follows with the background covered as we go:\n",
    "\n",
    "1. Read in the set of related data tables\n",
    "2. Create a featuretools `EntitySet` and add `entities` to it \n",
    "    * Identify correct variable types as required\n",
    "    * Identify indices in data\n",
    "3. Add relationships between `entities`\n",
    "4. Select feature primitives to use to create new features\n",
    "    * Use basic set of primitives\n",
    "    * Examine features that will be created\n",
    "5. Run Deep Feature Synthesis to generate thousands of new features\n",
    "\n",
    "\n",
    "## Problem and Dataset\n",
    "\n",
    "The [Home Credit Default Risk competition](https://www.kaggle.com/c/home-credit-default-risk) currently running on Kaggle is a supervised classification task where the objective is to predict whether or not an applicant for a loan (known as a client) will default on the loan. The data comprises socio-economic indicators for the clients, loan specific financial information, and comprehensive data on previous loans at Home Credit (the institution sponsoring the competition) and other credit agencies. The metric for this competition is Receiver Operating Characteristic Area Under the Curve (ROC AUC) with predictions made in terms of the probability of default. We can evaluate our submissions both through cross-validation on the training data (for which we have the labels) or by submitting our test predictions to Kaggle to see where we place on the public leaderboard (which is calculated with only 10% of the testing data). \n",
    "\n",
    "The Home Credit Default Risk dataset ([available for download here](https://www.kaggle.com/c/home-credit-default-risk/data)) consists of seven related tables of data:\n",
    "\n",
    "* application_train/application_test: the main training/testing data for each client at Home Credit. The information includes both socioeconomic indicators for the client and loan-specific characteristics. Each loan has its own row and is uniquely identified by the feature `SK_ID_CURR`. The training application data comes with the `TARGET` indicating 0: the loan was repaid or 1: the loan was not repaid. \n",
    "* bureau: data concerning client's previous credits from other financial institutions (not Home Credit). Each previous credit has its own row in bureau, but one client in the application data can have multiple previous credits. The previous credits are uniquely identified by the feature `SK_ID_BUREAU`.\n",
    "* bureau_balance: monthly balance data about the credits in bureau. Each row has information for one month about a previous credit and a single previous credit can have multiple rows. This is linked backed to the bureau loan data by `SK_ID_BUREAU` (not unique in this dataframe).\n",
    "* previous_application: previous applications for loans at Home Credit of clients who have loans in the application data. Each client in the application data can have multiple previous loans. Each previous application has one row in this dataframe and is uniquely identified by the feature `SK_ID_PREV`. \n",
    "* POS_CASH_BALANCE: monthly data about previous point of sale or cash loans from the previous loan data. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows. This is linked backed to the previous loan data by `SK_ID_PREV` (not unique in this dataframe).\n",
    "* credit_card_balance: monthly data about previous credit cards loans from the previous loan data. Each row is one month of a credit card balance, and a single credit card can have many rows. This is linked backed to the previous loan data by `SK_ID_PREV` (not unique in this dataframe).\n",
    "* installments_payment: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment. This is linked backed to the previous loan data by `SK_ID_PREV` (not unique in this dataframe).\n",
    "\n",
    "The image below shows the seven tables and the variables linking them:\n",
    "\n",
    "![](../images/kaggle_home_credit/home_credit_data.png)\n",
    "\n",
    "The variables that tie the tables together will be important to understand when it comes to adding `relationships` between entities. __The only domain knowledge we need for a full Featuretools approach to the problem is the indexes of the tables and the relationships between the tables.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# featuretools for automated feature engineering\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "First we can read in the seven data tables. We also replace the anomalous values previously identified (we did the same process with manual feature engineering). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets and replace the anomalous values\n",
    "app_train = pd.read_csv('input/application_train.csv').replace({365243: np.nan})\n",
    "app_test = pd.read_csv('input/application_test.csv').replace({365243: np.nan})\n",
    "bureau = pd.read_csv('input/bureau.csv').replace({365243: np.nan})\n",
    "bureau_balance = pd.read_csv('input/bureau_balance.csv').replace({365243: np.nan})\n",
    "cash = pd.read_csv('input/POS_CASH_balance.csv').replace({365243: np.nan})\n",
    "credit = pd.read_csv('input/credit_card_balance.csv').replace({365243: np.nan})\n",
    "previous = pd.read_csv('input/previous_application.csv').replace({365243: np.nan})\n",
    "installments = pd.read_csv('input/installments_payments.csv').replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join together the training and testing datasets to make sure we build the same features for each set. Later, after the feature matrix is built, we can separate out the two sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test['TARGET'] = np.nan\n",
    "\n",
    "# Join together training and testing\n",
    "app = pd.concat([app_train, app_test], ignore_index = True)\n",
    "app = app.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the indexes are an incorrect data type (floats) so we need to make these all the same (integers) for adding relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in ['SK_ID_CURR', 'SK_ID_PREV', 'SK_ID_BUREAU']:\n",
    "    for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "        if index in list(dataset.columns):\n",
    "            dataset[index] = dataset[index].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_train.to_csv('input/application_train.csv')\n",
    "# app_test.to_csv('input/application_test.csv')\n",
    "# bureau.to_csv('input/bureau.csv')\n",
    "# bureau_balance.to_csv('input/bureau_balance.csv')\n",
    "# cash.to_csv('input/POS_CASH_balance.csv')\n",
    "# credit.to_csv('input/credit_card_balance.csv')\n",
    "# previous.to_csv('input/previous_application.csv')\n",
    "# installments.to_csv('input/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuretools Basics\n",
    "\n",
    "[Featuretools](https://docs.featuretools.com/#minute-quick-start) is an open-source Python library for automatically creating features out of a set of related tables using a technique called [Deep Feature Synthesis](http://www.jmaxkanter.com/static/papers/DSAA_DSM_2015.pdf). Automated feature engineering, like many topics in machine learning, is a complex subject built upon a foundation of simpler ideas. By going through these ideas one at a time, we can build up our understanding of Featuretools which will later allow for us to get the most out of it.\n",
    "\n",
    "There are a few concepts that we will cover along the way:\n",
    "\n",
    "* [Entities and EntitySets](https://docs.featuretools.com/en/stable/loading_data/using_entitysets.html): our tables and a data structure for keeping track of them all\n",
    "* [Relationships between tables](https://docs.featuretools.com/en/stable/loading_data/using_entitysets.html#adding-a-relationship): how the tables can be related to one another\n",
    "* [Feature primitives](https://docs.featuretools.com/en/stable/automated_feature_engineering/primitives.html): aggregations and transformations that are stacked to build features\n",
    "* [Deep feature synthesis](https://docs.featuretools.com/en/stable/automated_feature_engineering/afe.html): the method that uses feature primitives to generate thousands of new features\n",
    "\n",
    "# Entities and Entitysets\n",
    "\n",
    "An entity is simply a table or in Pandas, a `dataframe`. The observations must be in the rows and the features in the columns. An entity in featuretools must have a unique index where none of the elements are duplicated.  Currently, only `app`, `bureau`, and `previous` have unique indices (`SK_ID_CURR`, `SK_ID_BUREAU`, and `SK_ID_PREV` respectively). For the other dataframes, when we create entities from them, we must pass in `make_index = True` and then specify the name of the index. \n",
    "\n",
    "Entities can also have time indices that represent when the information in the row became known. (There are not datetimes in any of the data, but there are relative times, given in months or days, that could be treated as time variables, although we will not use them as time in this notebook).\n",
    "\n",
    "An [EntitySet](https://docs.featuretools.com/en/stable/loading_data/using_entitysets.html) is a collection of tables and the relationships between them. This can be thought of a data structure with its own methods and attributes. Using an EntitySet allows us to group together multiple tables and will make creating the features much simpler than keeping track of individual tables and relationships. __EntitySets and entities are abstractions that can be applied to any dataset because they do not depend on the underlying data.__\n",
    "\n",
    "First we'll make an empty entityset named clients to keep track of all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Types\n",
    "\n",
    "Featuretools will automatically infer the variable types. However, there may be some cases where we need to explicitly tell featuretools the variable type such as when a boolean variable is represented as an integer. Variable types in featuretools can be specified as a dictionary. \n",
    "\n",
    "We will first work with the `app` data to specify the proper variable types. To identify the `Boolean` variables that are recorded as numbers (1.0 or 0.0), we can iterate through the data and find any columns where there are only 2 unique values and the data type is numeric. We can also use the column definitions to find any other data types that should be identified, such as `Ordinal` variables. Identifying the correct variable types is important because Featuretools applies different operations to different data types (just as we do when manual feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356250</th>\n",
       "      <td>456221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>412560.0</td>\n",
       "      <td>17473.5</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356251</th>\n",
       "      <td>456222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>622413.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356252</th>\n",
       "      <td>456223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>33205.5</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356253</th>\n",
       "      <td>456224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>25128.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356254</th>\n",
       "      <td>456250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>24709.5</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356255 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0           100002     1.0                   0             0                1   \n",
       "1           100003     0.0                   0             0                0   \n",
       "2           100004     0.0                   1             1                1   \n",
       "3           100006     0.0                   0             0                1   \n",
       "4           100007     0.0                   0             0                1   \n",
       "...            ...     ...                 ...           ...              ...   \n",
       "356250      456221     NaN                   0             0                1   \n",
       "356251      456222     NaN                   0             0                0   \n",
       "356252      456223     NaN                   0             1                1   \n",
       "356253      456224     NaN                   0             0                0   \n",
       "356254      456250     NaN                   0             1                0   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0                  0          202500.0    406597.5      24700.5   \n",
       "1                  0          270000.0   1293502.5      35698.5   \n",
       "2                  0           67500.0    135000.0       6750.0   \n",
       "3                  0          135000.0    312682.5      29686.5   \n",
       "4                  0          121500.0    513000.0      21865.5   \n",
       "...              ...               ...         ...          ...   \n",
       "356250             0          121500.0    412560.0      17473.5   \n",
       "356251             2          157500.0    622413.0      31909.5   \n",
       "356252             1          202500.0    315000.0      33205.5   \n",
       "356253             0          225000.0    450000.0      25128.0   \n",
       "356254             0          135000.0    312768.0      24709.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  ...  NAME_EDUCATION_TYPE  NAME_FAMILY_STATUS  \\\n",
       "0              351000.0  ...                    4                   3   \n",
       "1             1129500.0  ...                    1                   1   \n",
       "2              135000.0  ...                    4                   3   \n",
       "3              297000.0  ...                    4                   0   \n",
       "4              513000.0  ...                    4                   3   \n",
       "...                 ...  ...                  ...                 ...   \n",
       "356250         270000.0  ...                    4                   5   \n",
       "356251         495000.0  ...                    4                   1   \n",
       "356252         315000.0  ...                    4                   1   \n",
       "356253         450000.0  ...                    1                   1   \n",
       "356254         270000.0  ...                    4                   1   \n",
       "\n",
       "        NAME_HOUSING_TYPE  OCCUPATION_TYPE  WEEKDAY_APPR_PROCESS_START  \\\n",
       "0                       1                9                           6   \n",
       "1                       1                4                           1   \n",
       "2                       1                9                           1   \n",
       "3                       1                9                           6   \n",
       "4                       1                4                           4   \n",
       "...                   ...              ...                         ...   \n",
       "356250                  1                0                           6   \n",
       "356251                  1               15                           1   \n",
       "356252                  1                0                           6   \n",
       "356253                  1               11                           1   \n",
       "356254                  1                4                           5   \n",
       "\n",
       "        ORGANIZATION_TYPE  FONDKAPREMONT_MODE  HOUSETYPE_MODE  \\\n",
       "0                       5                   3               1   \n",
       "1                      39                   3               1   \n",
       "2                      11                   0               0   \n",
       "3                       5                   0               0   \n",
       "4                      37                   0               0   \n",
       "...                   ...                 ...             ...   \n",
       "356250                 33                   0               0   \n",
       "356251                 51                   0               0   \n",
       "356252                  5                   0               1   \n",
       "356253                 42                   0               1   \n",
       "356254                 11                   0               0   \n",
       "\n",
       "        WALLSMATERIAL_MODE  EMERGENCYSTATE_MODE  \n",
       "0                        6                    1  \n",
       "1                        1                    1  \n",
       "2                        0                    0  \n",
       "3                        0                    0  \n",
       "4                        0                    0  \n",
       "...                    ...                  ...  \n",
       "356250                   0                    0  \n",
       "356251                   0                    0  \n",
       "356252                   6                    1  \n",
       "356253                   5                    1  \n",
       "356254                   0                    0  \n",
       "\n",
       "[356255 rows x 122 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.features.generators import AutoMLPipelineFeatureGenerator\n",
    "g = AutoMLPipelineFeatureGenerator(post_generators=[], post_drop_duplicates=False)\n",
    "g.fit_transform(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category', [])  : 13 | ['CODE_GENDER', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', ...]\n",
      "('float', [])     : 67 | ['TARGET', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', ...]\n",
      "('int', [])       :  7 | ['SK_ID_CURR', 'CNT_CHILDREN', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH', 'REGION_RATING_CLIENT', ...]\n",
      "('int', ['bool']) : 35 | ['NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', ...]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json.dump(g.feature_metadata.to_dict(), open('test.json', 'w'))\n",
    "print(g.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import woodwork as ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "app.ww.init(name='app', index='SK_ID_CURR')\n",
    "bureau.ww.init(name='bureau', index='SK_ID_BUREAU')\n",
    "previous.ww.init(name='previous', index='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to identifying Boolean variables, we want to make sure featuretools does not create nonsense features such as statistical aggregations (mean, max, etc.) of ids. The `credit`, `cash`, and `installments` data all have the `SK_ID_CURR` variable. However, we do not actually need this variable in these dataframes because we link them to `app` through the `previous` dataframe with the `SK_ID_PREV` variable. \n",
    "\n",
    "We don't want to make features from `SK_ID_CURR` since it is an arbitrary id and should have no predictive power. \n",
    "Our options to handle these variables is either to tell featuretools to ignore them, or to drop the features before including them in the entityset. We will take the latter approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(app.columns) == len(g.feature_metadata.get_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in app.columns if c not in g.feature_metadata.get_features()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME_CONTRACT_TYPE']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agfs = set(g.feature_metadata.get_features(required_raw_special_pairs=[('category', [])]))\n",
    "wwfs = set(app.ww.select(['category']).columns)\n",
    "\n",
    "[c for c in wwfs if c not in agfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('int', ['bool'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.feature_metadata.get_feature_type_raw('NAME_CONTRACT_TYPE'), g.feature_metadata.get_feature_types_special('NAME_CONTRACT_TYPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "356250    NaN\n",
       "356251    NaN\n",
       "356252    NaN\n",
       "356253    NaN\n",
       "356254    NaN\n",
       "Name: TARGET, Length: 356255, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_CONTRACT_TYPE\n",
       "Cash loans         326537\n",
       "Revolving loans     29718\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app['NAME_CONTRACT_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(app.ww._get_typing_info()).to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments = installments.drop(columns = ['SK_ID_CURR'])\n",
    "credit = credit.drop(columns = ['SK_ID_CURR'])\n",
    "cash = cash.drop(columns = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww.list_logical_types().to_csv('ww_logical.csv')\n",
    "ww.list_semantic_tags().to_csv('ww_semantic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a      b     c          t\n",
      "1  1   True  True 2023-01-01\n",
      "2  2  False  True 2019-01-23\n",
      "3  3  False  True 2021-12-12\n",
      "4  4   <NA>  True 2022-12-11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Physical Type</th>\n",
       "      <th>Logical Type</th>\n",
       "      <th>Semantic Tag(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>int64</td>\n",
       "      <td>Integer</td>\n",
       "      <td>['index']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>string</td>\n",
       "      <td>NaturalLanguage</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>bool</td>\n",
       "      <td>Boolean</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>Datetime</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "         Physical Type     Logical Type Semantic Tag(s)\n",
       "Column                                                 \n",
       "a                int64          Integer       ['index']\n",
       "b               string  NaturalLanguage              []\n",
       "c                 bool          Boolean              []\n",
       "t       datetime64[ns]         Datetime              []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import woodwork\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1,2,3,4], 'b': [True, False, False,None],\n",
    "                   'c': [15, 15, 12, 15,],\n",
    "                   't': ['2023-01-01', '2019-01-23', '2021-12-12', '2022-12-11']})\n",
    "df.t = pd.to_datetime(df.t)\n",
    "g = AutoMLPipelineFeatureGenerator(post_generators=[], post_drop_duplicates=False)\n",
    "g.fit_transform(df)\n",
    "df.ww.init(name=None, logical_types={'c': 'Boolean', 'b': 'NaturalLanguage'})\n",
    "df.ww.set_index('a')\n",
    "print(df)\n",
    "df.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featuretools.entityset.entityset import _get_or_create_index\n",
    "_, index, df = _get_or_create_index('dfasdasd', True, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Physical Type</th>\n",
       "      <th>Logical Type</th>\n",
       "      <th>Semantic Tag(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dfasdasd</th>\n",
       "      <td>int64</td>\n",
       "      <td>Integer</td>\n",
       "      <td>['index']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>int64</td>\n",
       "      <td>Integer</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>int64</td>\n",
       "      <td>Integer</td>\n",
       "      <td>['numeric']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>string</td>\n",
       "      <td>NaturalLanguage</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>bool</td>\n",
       "      <td>Boolean</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>Datetime</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "           Physical Type     Logical Type Semantic Tag(s)\n",
       "Column                                                   \n",
       "dfasdasd           int64          Integer       ['index']\n",
       "df                 int64          Integer     ['numeric']\n",
       "a                  int64          Integer     ['numeric']\n",
       "b                 string  NaturalLanguage              []\n",
       "c                   bool          Boolean              []\n",
       "t         datetime64[ns]         Datetime              []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ww.init(schema=df.ww.schema, index = 'dfasdasd')\n",
    "\n",
    "df.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ww.set_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category', [])             : 1 | ['b']\n",
      "('int', [])                  : 1 | ['a']\n",
      "('int', ['bool'])            : 1 | ['c']\n",
      "('int', ['datetime_as_int']) : 5 | ['t', 't.year', 't.month', 't.day', 't.dayofweek']\n"
     ]
    }
   ],
   "source": [
    "print(g.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.common.features import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(g.feature_metadata.get_feature_types_special('b'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Entities\n",
    "\n",
    "Now we define each entity, or table of data, and add it to the `EntitySet`. We need to pass in an index if the table has one or `make_index = True` if not. In the cases where we need to make an index, we must supply a name for the index. We also need to pass in the dictionary of variable types if there are any specific variables we should identify. The following code adds all seven tables to the `EntitySet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity set with id applications\n",
    "es = ft.EntitySet(id = 'clients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/entityset/entityset.py:754: UserWarning: A Woodwork-initialized DataFrame was provided, so the following parameters were ignored: index\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/woodwork/type_sys/utils.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# Entities with a unique index\n",
    "es = es.add_dataframe(dataframe_name='app', dataframe = app, index = 'SK_ID_CURR')\n",
    "\n",
    "es = es.add_dataframe(dataframe_name='bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "\n",
    "es = es.add_dataframe(dataframe_name='previous', dataframe = previous, index = 'SK_ID_PREV')\n",
    "\n",
    "# Entities that do not have a unique index\n",
    "es = es.add_dataframe(dataframe_name='bureau_balance', dataframe = bureau_balance, \n",
    "                              make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "es = es.add_dataframe(dataframe_name='cash', dataframe = cash, \n",
    "                              make_index = True, index = 'cash_index')\n",
    "\n",
    "es = es.add_dataframe(dataframe_name='installments', dataframe = installments,\n",
    "                              make_index = True, index = 'installments_index')\n",
    "\n",
    "es = es.add_dataframe(dataframe_name='credit', dataframe = credit,\n",
    "                              make_index = True, index = 'credit_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  DataFrames:\n",
       "    app [Rows: 356255, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 8]\n",
       "    installments [Rows: 13605401, Columns: 8]\n",
       "    credit [Rows: 3840312, Columns: 23]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display entityset so far\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `EntitySet` allows us to group together all of our tables as one data structure. This is much easier than manipulating the tables one at a time (as we have to do in manual feature engineering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationships\n",
    "\n",
    "Relationships are a fundamental concept not only in featuretools, but in any relational database. The most common type of relationship is one-to-many. The best way to think of a one-to-many relationship is with the analogy of parent-to-child. A parent is a single individual, but can have mutliple children. In the context of tables, a parent table will have one row (observation) for every individual while a child table can have many observations for each parent.  In a _parent table_, each individual has a single row and is uniquely identified by an index (also called a key). Each individual in the parent table can have multiple rows in the _child table_. Things get a little more complicated because children tables can have children of their own, making these grandchildren of the original parent. \n",
    "\n",
    "As an example of a parent-to-child relationship, the `app` dataframe has one row for each client (identified by `SK_ID_CURR`) while the `bureau` dataframe has multiple previous loans for each client. Therefore, the `bureau` dataframe is the child of the `app` dataframe. The `bureau` dataframe in turn is the parent of `bureau_balance` because each loan has one row in `bureau` (identified by `SK_ID_BUREAU`) but multiple monthly records in `bureau_balance`. When we do manual feature engineering, keeping track of all these relationships is a massive time investment (and a potential source of error), but we can add these relationships to our `EntitySet` and let featuretools worry about keeping the tables straight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: app, Parent Variable of bureau: SK_ID_CURR\n",
      "\n",
      "         FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20\n",
      "100002                 0                 0                 0                 0\n",
      "100003                 0                 0                 0                 0\n",
      "100004                 0                 0                 0                 0\n",
      "100006                 0                 0                 0                 0\n",
      "100007                 0                 0                 0                 0\n",
      "\n",
      "Child: bureau, Child Variable of app: SK_ID_CURR\n",
      "\n",
      "          SK_ID_CURR  SK_ID_BUREAU CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT\n",
      "5714462      215354       5714462        Closed      currency 1         -497\n",
      "5714463      215354       5714463        Active      currency 1         -208\n",
      "5714464      215354       5714464        Active      currency 1         -203\n",
      "5714465      215354       5714465        Active      currency 1         -203\n",
      "5714466      215354       5714466        Active      currency 1         -629\n"
     ]
    }
   ],
   "source": [
    "print('Parent: app, Parent Variable of bureau: SK_ID_CURR\\n\\n', app.iloc[:, 111:115].head())\n",
    "print('\\nChild: bureau, Child Variable of app: SK_ID_CURR\\n\\n', bureau.iloc[:, :5].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SK_ID_CURR` 215354 has one row in the parent table and multiple rows in the child. \n",
    "\n",
    "Two tables are linked via a shared variable. The `app` and `bureau` dataframe are linked by the `SK_ID_CURR` variable while the `bureau` and `bureau_balance` dataframes are linked with the `SK_ID_BUREAU`. The linking variable is called the `parent` variable in the parent table and the `child` variable in the child table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: bureau, Parent Variable of bureau_balance: SK_ID_BUREAU\n",
      "\n",
      "          SK_ID_CURR  SK_ID_BUREAU CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT\n",
      "5714462      215354       5714462        Closed      currency 1         -497\n",
      "5714463      215354       5714463        Active      currency 1         -208\n",
      "5714464      215354       5714464        Active      currency 1         -203\n",
      "5714465      215354       5714465        Active      currency 1         -203\n",
      "5714466      215354       5714466        Active      currency 1         -629\n",
      "\n",
      "Child: bureau_balance, Child Variable of bureau: SK_ID_BUREAU\n",
      "\n",
      "    bureaubalance_index  SK_ID_BUREAU  MONTHS_BALANCE STATUS\n",
      "0                    0       5715448               0      C\n",
      "1                    1       5715448              -1      C\n",
      "2                    2       5715448              -2      C\n",
      "3                    3       5715448              -3      C\n",
      "4                    4       5715448              -4      C\n"
     ]
    }
   ],
   "source": [
    "print('Parent: bureau, Parent Variable of bureau_balance: SK_ID_BUREAU\\n\\n', bureau.iloc[:, :5].head())\n",
    "print('\\nChild: bureau_balance, Child Variable of bureau: SK_ID_BUREAU\\n\\n', bureau_balance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, we use the relationships between parents and children to aggregate data by grouping together all the children for a single parent and calculating statistics. For example, we might group together all the loans for a single client and calculate the average loan amount. This is straightforward, but can grow extremely tedious when we want to make hundreds of these features. Doing so one at a time is extremely inefficient especially because we end up re-writing much of the code over and over again and this code cannot be used for any different problem! \n",
    "\n",
    "Things get even worse when we have to aggregate the grandchildren because we have to use two steps: first aggregate at the parent level, and then at the grandparent level. Soon we will see that Featuretools can do this work automatically for us, generating thousands of features from __all__ of the data tables. When we did this manually it took about 15 minutes per feature so Featuretools potentially saves us hundreds of hours.\n",
    "\n",
    "### Adding Relationships\n",
    "\n",
    "Defining the relationships is straightforward using the diagram for the data tables. For each relationship, we need to first specify the parent variable and then the child variable. Altogether, there are a total of 6 relationships between the tables (counting the training and testing relationships as one). Below we specify these relationships and then add them to the EntitySet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between app_train and bureau\n",
    "r_app_bureau = ('app', 'SK_ID_CURR', 'bureau', 'SK_ID_CURR',)\n",
    "\n",
    "# Relationship between bureau and bureau balance\n",
    "r_bureau_balance = ('bureau', 'SK_ID_BUREAU', 'bureau_balance', 'SK_ID_BUREAU',)\n",
    "\n",
    "# Relationship between current app and previous apps\n",
    "r_app_previous = ('app', 'SK_ID_CURR', 'previous', 'SK_ID_CURR',)\n",
    "\n",
    "# Relationships between previous apps and cash, installments, and credit\n",
    "r_previous_cash = ('previous', 'SK_ID_PREV', 'cash', 'SK_ID_PREV',)\n",
    "r_previous_installments = ('previous', 'SK_ID_PREV', 'installments', 'SK_ID_PREV',)\n",
    "r_previous_credit = ('previous', 'SK_ID_PREV', 'credit', 'SK_ID_PREV',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  DataFrames:\n",
       "    app [Rows: 356255, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 8]\n",
       "    installments [Rows: 13605401, Columns: 8]\n",
       "    credit [Rows: 3840312, Columns: 23]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in the defined relationships\n",
    "es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
    "                           r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "# Print out the EntitySet\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see the benefits of using an `EntitySet` that is able to track all of the relationships for us. This allows us to work at a higher level of abstraction, thinking about the entire dataset rather than each individual table, greatly increasing our efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Slightly advanced note__: we need to be careful to not create a [diamond graph](https://en.wikipedia.org/wiki/Diamond_graph) where there are multiple paths from a parent to a child. If we directly link `app` and `cash` via `SK_ID_CURR`; `previous` and `cash` via `SK_ID_PREV`; and `app` and `previous` via `SK_ID_CURR`, then we have created two paths from `app` to `cash`. This results in ambiguity, so the approach we have to take instead is to link `app` to `cash` through `previous`. We establish a relationship between `previous` (the parent) and `cash` (the child) using `SK_ID_PREV`. Then we establish a relationship between `app` (the parent) and `previous` (now the child) using `SK_ID_CURR`. Then featuretools will be able to create features on `app` derived from both `previous` and `cash` by stacking multiple primitives. \n",
    "\n",
    "If this doesn't make too much sense, then just remember to only include one path from a parent to any descendents. For example, link a grandparent to a grandchild through the parent instead of directly through a shared variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All entities in the entity can be linked through these relationships. In theory this allows us to calculate features for any of the entities, but in practice, we will only calculate features for the `app` dataframe since that will be used for training/testing. The end outcome will be a dataframe that has one row for each client in `app` with thousands of features for each individual. \n",
    "\n",
    "We are almost to the point where we can start creating thousands of features but we still have a few foundational topics to understand. The next building block to cover is feature primitives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: clients Pages: 1 -->\n",
       "<svg width=\"1207pt\" height=\"2906pt\"\n",
       " viewBox=\"0.00 0.00 1206.50 2906.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 2902)\">\n",
       "<title>clients</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-2902 1202.5,-2902 1202.5,4 -4,4\"/>\n",
       "<!-- app -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>app</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"241,-0.5 241,-1861.5 582,-1861.5 582,-0.5 241,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.5\" y=\"-1846.3\" font-family=\"Times,serif\" font-size=\"14.00\">app (356255 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"241,-1838.5 582,-1838.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1823.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_CURR : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1808.3\" font-family=\"Times,serif\" font-size=\"14.00\">TARGET : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1793.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CONTRACT_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1778.3\" font-family=\"Times,serif\" font-size=\"14.00\">CODE_GENDER : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1763.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_OWN_CAR : Boolean</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1748.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_OWN_REALTY : Boolean</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1733.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_CHILDREN : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1718.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_INCOME_TOTAL : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1703.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1688.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_ANNUITY : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1673.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_GOODS_PRICE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1658.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_TYPE_SUITE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1643.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_INCOME_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1628.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_EDUCATION_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1613.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_FAMILY_STATUS : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1598.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_HOUSING_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1583.3\" font-family=\"Times,serif\" font-size=\"14.00\">REGION_POPULATION_RELATIVE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1568.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_BIRTH : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1553.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_EMPLOYED : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1538.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_REGISTRATION : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1523.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_ID_PUBLISH : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1508.3\" font-family=\"Times,serif\" font-size=\"14.00\">OWN_CAR_AGE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1493.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_MOBIL : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1478.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_EMP_PHONE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1463.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_WORK_PHONE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1448.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_CONT_MOBILE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1433.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_PHONE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1418.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_EMAIL : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1403.3\" font-family=\"Times,serif\" font-size=\"14.00\">OCCUPATION_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1388.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_FAM_MEMBERS : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1373.3\" font-family=\"Times,serif\" font-size=\"14.00\">REGION_RATING_CLIENT : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1358.3\" font-family=\"Times,serif\" font-size=\"14.00\">REGION_RATING_CLIENT_W_CITY : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1343.3\" font-family=\"Times,serif\" font-size=\"14.00\">WEEKDAY_APPR_PROCESS_START : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1328.3\" font-family=\"Times,serif\" font-size=\"14.00\">HOUR_APPR_PROCESS_START : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1313.3\" font-family=\"Times,serif\" font-size=\"14.00\">REG_REGION_NOT_LIVE_REGION : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1298.3\" font-family=\"Times,serif\" font-size=\"14.00\">REG_REGION_NOT_WORK_REGION : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1283.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVE_REGION_NOT_WORK_REGION : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1268.3\" font-family=\"Times,serif\" font-size=\"14.00\">REG_CITY_NOT_LIVE_CITY : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1253.3\" font-family=\"Times,serif\" font-size=\"14.00\">REG_CITY_NOT_WORK_CITY : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1238.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVE_CITY_NOT_WORK_CITY : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1223.3\" font-family=\"Times,serif\" font-size=\"14.00\">ORGANIZATION_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1208.3\" font-family=\"Times,serif\" font-size=\"14.00\">EXT_SOURCE_1 : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1193.3\" font-family=\"Times,serif\" font-size=\"14.00\">EXT_SOURCE_2 : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1178.3\" font-family=\"Times,serif\" font-size=\"14.00\">EXT_SOURCE_3 : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1163.3\" font-family=\"Times,serif\" font-size=\"14.00\">APARTMENTS_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1148.3\" font-family=\"Times,serif\" font-size=\"14.00\">BASEMENTAREA_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1133.3\" font-family=\"Times,serif\" font-size=\"14.00\">YEARS_BEGINEXPLUATATION_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1118.3\" font-family=\"Times,serif\" font-size=\"14.00\">YEARS_BUILD_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1103.3\" font-family=\"Times,serif\" font-size=\"14.00\">COMMONAREA_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1088.3\" font-family=\"Times,serif\" font-size=\"14.00\">ELEVATORS_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1073.3\" font-family=\"Times,serif\" font-size=\"14.00\">ENTRANCES_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1058.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLOORSMAX_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1043.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLOORSMIN_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1028.3\" font-family=\"Times,serif\" font-size=\"14.00\">LANDAREA_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-1013.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVINGAPARTMENTS_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-998.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVINGAREA_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-983.3\" font-family=\"Times,serif\" font-size=\"14.00\">NONLIVINGAPARTMENTS_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-968.3\" font-family=\"Times,serif\" font-size=\"14.00\">NONLIVINGAREA_AVG : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-953.3\" font-family=\"Times,serif\" font-size=\"14.00\">APARTMENTS_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-938.3\" font-family=\"Times,serif\" font-size=\"14.00\">BASEMENTAREA_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-923.3\" font-family=\"Times,serif\" font-size=\"14.00\">YEARS_BEGINEXPLUATATION_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-908.3\" font-family=\"Times,serif\" font-size=\"14.00\">YEARS_BUILD_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-893.3\" font-family=\"Times,serif\" font-size=\"14.00\">COMMONAREA_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-878.3\" font-family=\"Times,serif\" font-size=\"14.00\">ELEVATORS_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-863.3\" font-family=\"Times,serif\" font-size=\"14.00\">ENTRANCES_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-848.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLOORSMAX_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-833.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLOORSMIN_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-818.3\" font-family=\"Times,serif\" font-size=\"14.00\">LANDAREA_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-803.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVINGAPARTMENTS_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-788.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVINGAREA_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-773.3\" font-family=\"Times,serif\" font-size=\"14.00\">NONLIVINGAPARTMENTS_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-758.3\" font-family=\"Times,serif\" font-size=\"14.00\">NONLIVINGAREA_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-743.3\" font-family=\"Times,serif\" font-size=\"14.00\">APARTMENTS_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-728.3\" font-family=\"Times,serif\" font-size=\"14.00\">BASEMENTAREA_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-713.3\" font-family=\"Times,serif\" font-size=\"14.00\">YEARS_BEGINEXPLUATATION_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-698.3\" font-family=\"Times,serif\" font-size=\"14.00\">YEARS_BUILD_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-683.3\" font-family=\"Times,serif\" font-size=\"14.00\">COMMONAREA_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-668.3\" font-family=\"Times,serif\" font-size=\"14.00\">ELEVATORS_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-653.3\" font-family=\"Times,serif\" font-size=\"14.00\">ENTRANCES_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-638.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLOORSMAX_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-623.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLOORSMIN_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-608.3\" font-family=\"Times,serif\" font-size=\"14.00\">LANDAREA_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-593.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVINGAPARTMENTS_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-578.3\" font-family=\"Times,serif\" font-size=\"14.00\">LIVINGAREA_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-563.3\" font-family=\"Times,serif\" font-size=\"14.00\">NONLIVINGAPARTMENTS_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-548.3\" font-family=\"Times,serif\" font-size=\"14.00\">NONLIVINGAREA_MEDI : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-533.3\" font-family=\"Times,serif\" font-size=\"14.00\">FONDKAPREMONT_MODE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">HOUSETYPE_MODE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-503.3\" font-family=\"Times,serif\" font-size=\"14.00\">TOTALAREA_MODE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-488.3\" font-family=\"Times,serif\" font-size=\"14.00\">WALLSMATERIAL_MODE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-473.3\" font-family=\"Times,serif\" font-size=\"14.00\">EMERGENCYSTATE_MODE : BooleanNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-458.3\" font-family=\"Times,serif\" font-size=\"14.00\">OBS_30_CNT_SOCIAL_CIRCLE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-443.3\" font-family=\"Times,serif\" font-size=\"14.00\">DEF_30_CNT_SOCIAL_CIRCLE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-428.3\" font-family=\"Times,serif\" font-size=\"14.00\">OBS_60_CNT_SOCIAL_CIRCLE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-413.3\" font-family=\"Times,serif\" font-size=\"14.00\">DEF_60_CNT_SOCIAL_CIRCLE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-398.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_LAST_PHONE_CHANGE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-383.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_2 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-368.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_3 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-353.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_4 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-338.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_5 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-323.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_6 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-308.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_7 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-293.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_8 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-278.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_9 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-263.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_10 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-248.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_11 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-233.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_12 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-218.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_13 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-203.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_14 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_15 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-173.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_16 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_17 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-143.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_18 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-128.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_19 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-113.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_20 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-98.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_DOCUMENT_21 : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-83.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_REQ_CREDIT_BUREAU_HOUR : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_REQ_CREDIT_BUREAU_DAY : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_REQ_CREDIT_BUREAU_WEEK : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-38.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_REQ_CREDIT_BUREAU_MON : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-23.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_REQ_CREDIT_BUREAU_QRT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_REQ_CREDIT_BUREAU_YEAR : IntegerNullable</text>\n",
       "</g>\n",
       "<!-- bureau -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>bureau</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"115.5,-2048.5 115.5,-2334.5 389.5,-2334.5 389.5,-2048.5 115.5,-2048.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"252.5\" y=\"-2319.3\" font-family=\"Times,serif\" font-size=\"14.00\">bureau (1716428 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"115.5,-2311.5 389.5,-2311.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2296.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_CURR : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2281.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_BUREAU : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2266.3\" font-family=\"Times,serif\" font-size=\"14.00\">CREDIT_ACTIVE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2251.3\" font-family=\"Times,serif\" font-size=\"14.00\">CREDIT_CURRENCY : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2236.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_CREDIT : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2221.3\" font-family=\"Times,serif\" font-size=\"14.00\">CREDIT_DAY_OVERDUE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2206.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_CREDIT_ENDDATE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2191.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_ENDDATE_FACT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2176.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT_MAX_OVERDUE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2161.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_CREDIT_PROLONG : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2146.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT_SUM : Double</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2131.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT_SUM_DEBT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2116.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT_SUM_LIMIT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2101.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT_SUM_OVERDUE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2086.3\" font-family=\"Times,serif\" font-size=\"14.00\">CREDIT_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2071.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_CREDIT_UPDATE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"123.5\" y=\"-2056.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_ANNUITY : Double</text>\n",
       "</g>\n",
       "<!-- bureau&#45;&gt;app -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>bureau&#45;&gt;app</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M315.25,-2048.44C315.25,-2048.44 315.25,-1871.68 315.25,-1871.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318.75,-1871.68 315.25,-1861.68 311.75,-1871.68 318.75,-1871.68\"/>\n",
       "<text text-anchor=\"middle\" x=\"274.25\" y=\"-1963.86\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_CURR</text>\n",
       "</g>\n",
       "<!-- previous -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>previous</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"475,-1898.5 475,-2484.5 800,-2484.5 800,-1898.5 475,-1898.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"637.5\" y=\"-2469.3\" font-family=\"Times,serif\" font-size=\"14.00\">previous (1670214 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"475,-2461.5 800,-2461.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2446.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2431.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_CURR : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2416.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CONTRACT_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2401.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_ANNUITY : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2386.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_APPLICATION : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2371.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2356.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_DOWN_PAYMENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2341.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_GOODS_PRICE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2326.3\" font-family=\"Times,serif\" font-size=\"14.00\">WEEKDAY_APPR_PROCESS_START : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2311.3\" font-family=\"Times,serif\" font-size=\"14.00\">HOUR_APPR_PROCESS_START : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2296.3\" font-family=\"Times,serif\" font-size=\"14.00\">FLAG_LAST_APPL_PER_CONTRACT : Boolean</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2281.3\" font-family=\"Times,serif\" font-size=\"14.00\">NFLAG_LAST_APPL_IN_DAY : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2266.3\" font-family=\"Times,serif\" font-size=\"14.00\">RATE_DOWN_PAYMENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2251.3\" font-family=\"Times,serif\" font-size=\"14.00\">RATE_INTEREST_PRIMARY : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2236.3\" font-family=\"Times,serif\" font-size=\"14.00\">RATE_INTEREST_PRIVILEGED : Double</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2221.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CASH_LOAN_PURPOSE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2206.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CONTRACT_STATUS : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2191.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_DECISION : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2176.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_PAYMENT_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2161.3\" font-family=\"Times,serif\" font-size=\"14.00\">CODE_REJECT_REASON : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2146.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_TYPE_SUITE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2131.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CLIENT_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2116.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_GOODS_CATEGORY : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2101.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_PORTFOLIO : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2086.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_PRODUCT_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2071.3\" font-family=\"Times,serif\" font-size=\"14.00\">CHANNEL_TYPE : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2056.3\" font-family=\"Times,serif\" font-size=\"14.00\">SELLERPLACE_AREA : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2041.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_SELLER_INDUSTRY : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2026.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_PAYMENT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-2011.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_YIELD_GROUP : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1996.3\" font-family=\"Times,serif\" font-size=\"14.00\">PRODUCT_COMBINATION : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1981.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_FIRST_DRAWING : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1966.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_FIRST_DUE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1951.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_LAST_DUE_1ST_VERSION : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1936.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_LAST_DUE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1921.3\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_TERMINATION : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"483\" y=\"-1906.3\" font-family=\"Times,serif\" font-size=\"14.00\">NFLAG_INSURED_ON_APPROVAL : IntegerNullable</text>\n",
       "</g>\n",
       "<!-- previous&#45;&gt;app -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>previous&#45;&gt;app</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M528.5,-1898.35C528.5,-1898.35 528.5,-1871.68 528.5,-1871.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"532,-1871.68 528.5,-1861.68 525,-1871.68 532,-1871.68\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.5\" y=\"-1873.82\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_CURR</text>\n",
       "</g>\n",
       "<!-- bureau_balance -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>bureau_balance</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-2664 0,-2755 239,-2755 239,-2664 0,-2664\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.5\" y=\"-2739.8\" font-family=\"Times,serif\" font-size=\"14.00\">bureau_balance (27299925 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-2732 239,-2732 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2716.8\" font-family=\"Times,serif\" font-size=\"14.00\">bureaubalance_index : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2701.8\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_BUREAU : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2686.8\" font-family=\"Times,serif\" font-size=\"14.00\">MONTHS_BALANCE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-2671.8\" font-family=\"Times,serif\" font-size=\"14.00\">STATUS : Categorical</text>\n",
       "</g>\n",
       "<!-- bureau_balance&#45;&gt;bureau -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>bureau_balance&#45;&gt;bureau</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.25,-2663.98C177.25,-2663.98 177.25,-2344.65 177.25,-2344.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.75,-2344.65 177.25,-2334.65 173.75,-2344.65 180.75,-2344.65\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.75\" y=\"-2508.12\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_BUREAU</text>\n",
       "</g>\n",
       "<!-- cash -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>cash</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"257,-2634 257,-2785 550,-2785 550,-2634 257,-2634\"/>\n",
       "<text text-anchor=\"middle\" x=\"403.5\" y=\"-2769.8\" font-family=\"Times,serif\" font-size=\"14.00\">cash (10001358 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"257,-2762 550,-2762 \"/>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2746.8\" font-family=\"Times,serif\" font-size=\"14.00\">cash_index : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2731.8\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2716.8\" font-family=\"Times,serif\" font-size=\"14.00\">MONTHS_BALANCE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2701.8\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_INSTALMENT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2686.8\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_INSTALMENT_FUTURE : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2671.8\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CONTRACT_STATUS : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2656.8\" font-family=\"Times,serif\" font-size=\"14.00\">SK_DPD : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-2641.8\" font-family=\"Times,serif\" font-size=\"14.00\">SK_DPD_DEF : Integer</text>\n",
       "</g>\n",
       "<!-- cash&#45;&gt;previous -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>cash&#45;&gt;previous</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M512.5,-2633.9C512.5,-2633.9 512.5,-2494.5 512.5,-2494.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"516,-2494.5 512.5,-2484.5 509,-2494.5 516,-2494.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"472.5\" y=\"-2568\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV</text>\n",
       "</g>\n",
       "<!-- installments -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>installments</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"568.5,-2634 568.5,-2785 840.5,-2785 840.5,-2634 568.5,-2634\"/>\n",
       "<text text-anchor=\"middle\" x=\"704.5\" y=\"-2769.8\" font-family=\"Times,serif\" font-size=\"14.00\">installments (13605401 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"568.5,-2762 840.5,-2762 \"/>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2746.8\" font-family=\"Times,serif\" font-size=\"14.00\">installments_index : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2731.8\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2716.8\" font-family=\"Times,serif\" font-size=\"14.00\">NUM_INSTALMENT_VERSION : Double</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2701.8\" font-family=\"Times,serif\" font-size=\"14.00\">NUM_INSTALMENT_NUMBER : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2686.8\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_INSTALMENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2671.8\" font-family=\"Times,serif\" font-size=\"14.00\">DAYS_ENTRY_PAYMENT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2656.8\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_INSTALMENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"576.5\" y=\"-2641.8\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_PAYMENT : Double</text>\n",
       "</g>\n",
       "<!-- installments&#45;&gt;previous -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>installments&#45;&gt;previous</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M645.67,-2633.9C645.67,-2633.9 645.67,-2494.5 645.67,-2494.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"649.17,-2494.5 645.67,-2484.5 642.17,-2494.5 649.17,-2494.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"605.67\" y=\"-2568\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV</text>\n",
       "</g>\n",
       "<!-- credit -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>credit</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"858.5,-2521.5 858.5,-2897.5 1198.5,-2897.5 1198.5,-2521.5 858.5,-2521.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1028.5\" y=\"-2882.3\" font-family=\"Times,serif\" font-size=\"14.00\">credit (3840312 rows)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"858.5,-2874.5 1198.5,-2874.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2859.3\" font-family=\"Times,serif\" font-size=\"14.00\">credit_index : Integer; index</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2844.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV : Integer; foreign_key</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2829.3\" font-family=\"Times,serif\" font-size=\"14.00\">MONTHS_BALANCE : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2814.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_BALANCE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2799.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_CREDIT_LIMIT_ACTUAL : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2784.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_DRAWINGS_ATM_CURRENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2769.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_DRAWINGS_CURRENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2754.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_DRAWINGS_OTHER_CURRENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2739.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_DRAWINGS_POS_CURRENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2724.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_INST_MIN_REGULARITY : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2709.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_PAYMENT_CURRENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2694.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_PAYMENT_TOTAL_CURRENT : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2679.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_RECEIVABLE_PRINCIPAL : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2664.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_RECIVABLE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2649.3\" font-family=\"Times,serif\" font-size=\"14.00\">AMT_TOTAL_RECEIVABLE : Double</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2634.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_DRAWINGS_ATM_CURRENT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2619.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_DRAWINGS_CURRENT : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2604.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_DRAWINGS_OTHER_CURRENT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2589.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_DRAWINGS_POS_CURRENT : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2574.3\" font-family=\"Times,serif\" font-size=\"14.00\">CNT_INSTALMENT_MATURE_CUM : IntegerNullable</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2559.3\" font-family=\"Times,serif\" font-size=\"14.00\">NAME_CONTRACT_STATUS : Categorical</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2544.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_DPD : Integer</text>\n",
       "<text text-anchor=\"start\" x=\"866.5\" y=\"-2529.3\" font-family=\"Times,serif\" font-size=\"14.00\">SK_DPD_DEF : Integer</text>\n",
       "</g>\n",
       "<!-- credit&#45;&gt;previous -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>credit&#45;&gt;previous</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M858.24,-2577C788.05,-2577 722.83,-2577 722.83,-2577 722.83,-2577 722.83,-2494.66 722.83,-2494.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"726.33,-2494.66 722.83,-2484.66 719.33,-2494.66 726.33,-2494.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"709.37\" y=\"-2580.8\" font-family=\"Times,serif\" font-size=\"14.00\">SK_ID_PREV</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fa1dd84e2c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Primitives\n",
    "\n",
    "A [feature primitive](https://docs.featuretools.com/en/stable/automated_feature_engineering/primitives.html) is an operation applied to a table or a set of tables to create a feature. These represent simple calculations, many of which we already use in manual feature engineering, that can be stacked on top of each other to create complex deep features. Feature primitives fall into two categories:\n",
    "\n",
    "* __Aggregation__: function that groups together children for each parent and calculates a statistic such as mean, min, max, or standard deviation across the children. An example is the maximum previous loan amount for each client. An aggregation covers multiple tables using relationships between tables.\n",
    "* __Transformation__: an operation applied to one or more columns in a single table. An example would be taking the absolute value of a column, or finding the difference between two columns in one table.\n",
    "\n",
    "A list of the available features primitives in featuretools can be viewed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>dask_compatible</th>\n",
       "      <th>spark_compatible</th>\n",
       "      <th>description</th>\n",
       "      <th>valid_inputs</th>\n",
       "      <th>return_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_unique_days</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the number of unique days.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count_less_than</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the number of values less than a controllable threshold.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_consecutive_positives</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the maximum number of consecutive positive values in the input</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer)&gt;, &lt;ColumnSchema (Logical Type = Double)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_consecutive_less_mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the length of the longest subsequence below the mean.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_count</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Calculates the number of occurrences of the min value in a list</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is_monotonically_decreasing</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines if a series is monotonically decreasing.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is_monotonically_increasing</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines if a series is monotonically increasing.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_outside_nth_std</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the number of observations that lie outside the first N standard deviations.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is_unique</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines whether or not a series of discrete is all unique.</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['category'])&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Calculates if all values are 'True' in a list.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;, &lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name         type  dask_compatible  \\\n",
       "0                n_unique_days  aggregation            False   \n",
       "1              count_less_than  aggregation            False   \n",
       "2    max_consecutive_positives  aggregation            False   \n",
       "3    num_consecutive_less_mean  aggregation            False   \n",
       "4                    min_count  aggregation            False   \n",
       "5  is_monotonically_decreasing  aggregation            False   \n",
       "6  is_monotonically_increasing  aggregation            False   \n",
       "7        count_outside_nth_std  aggregation            False   \n",
       "8                    is_unique  aggregation            False   \n",
       "9                          all  aggregation             True   \n",
       "\n",
       "   spark_compatible  \\\n",
       "0             False   \n",
       "1             False   \n",
       "2             False   \n",
       "3             False   \n",
       "4             False   \n",
       "5             False   \n",
       "6             False   \n",
       "7             False   \n",
       "8             False   \n",
       "9             False   \n",
       "\n",
       "                                                                               description  \\\n",
       "0                                                    Determines the number of unique days.   \n",
       "1                      Determines the number of values less than a controllable threshold.   \n",
       "2                Determines the maximum number of consecutive positive values in the input   \n",
       "3                         Determines the length of the longest subsequence below the mean.   \n",
       "4                          Calculates the number of occurrences of the min value in a list   \n",
       "5                                      Determines if a series is monotonically decreasing.   \n",
       "6                                      Determines if a series is monotonically increasing.   \n",
       "7  Determines the number of observations that lie outside the first N standard deviations.   \n",
       "8                            Determines whether or not a series of discrete is all unique.   \n",
       "9                                           Calculates if all values are 'True' in a list.   \n",
       "\n",
       "                                                                               valid_inputs  \\\n",
       "0                                                  <ColumnSchema (Logical Type = Datetime)>   \n",
       "1                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "2           <ColumnSchema (Logical Type = Integer)>, <ColumnSchema (Logical Type = Double)>   \n",
       "3                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "4                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "5                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "6                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "7                                              <ColumnSchema (Semantic Tags = ['numeric'])>   \n",
       "8                                             <ColumnSchema (Semantic Tags = ['category'])>   \n",
       "9  <ColumnSchema (Logical Type = Boolean)>, <ColumnSchema (Logical Type = BooleanNullable)>   \n",
       "\n",
       "                                                                     return_type  \n",
       "0          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "1          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "2          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "3  <ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])>  \n",
       "4  <ColumnSchema (Logical Type = IntegerNullable) (Semantic Tags = ['numeric'])>  \n",
       "5                                <ColumnSchema (Logical Type = BooleanNullable)>  \n",
       "6                                <ColumnSchema (Logical Type = BooleanNullable)>  \n",
       "7          <ColumnSchema (Logical Type = Integer) (Semantic Tags = ['numeric'])>  \n",
       "8                                <ColumnSchema (Logical Type = BooleanNullable)>  \n",
       "9                                        <ColumnSchema (Logical Type = Boolean)>  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the primitives in a dataframe\n",
    "primitives = ft.list_primitives()\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "primitives[primitives['type'] == 'aggregation'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>dask_compatible</th>\n",
       "      <th>spark_compatible</th>\n",
       "      <th>description</th>\n",
       "      <th>valid_inputs</th>\n",
       "      <th>return_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>haversine</td>\n",
       "      <td>transform</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Calculates the approximate haversine distance between two LatLong columns.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = LatLong)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>diff_datetime</td>\n",
       "      <td>transform</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Computes the timedelta between a datetime in a list and the previous datetime in that list.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Timedelta)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>year</td>\n",
       "      <td>transform</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Determines the year value of a datetime.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Ordinal: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>expanding_min</td>\n",
       "      <td>transform</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Computes the expanding minimum of events over a given window.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])&gt;, &lt;ColumnSchema (Semant...</td>\n",
       "      <td>&lt;ColumnSchema (Semantic Tags = ['numeric'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>hour</td>\n",
       "      <td>transform</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Determines the hour value of a datetime.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Ordinal: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>lag</td>\n",
       "      <td>transform</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Shifts an array of values by a specified number of periods.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;, &lt;ColumnSchema (Semantic Tags = ['time_index'])&gt;, &lt;Colum...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>is_year_start</td>\n",
       "      <td>transform</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Determines if a date falls on the start of a year.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Datetime)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>two_digit_postal_code</td>\n",
       "      <td>transform</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Returns the two digit prefix of a given postal code.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = PostalCode)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Categorical) (Semantic Tags = ['category'])&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>or</td>\n",
       "      <td>transform</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Performs element-wise logical OR of two lists.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Boolean)&gt;, &lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = BooleanNullable)&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>url_to_protocol</td>\n",
       "      <td>transform</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determines the protocol (http or https) of a url.</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = URL)&gt;</td>\n",
       "      <td>&lt;ColumnSchema (Logical Type = Categorical) (Semantic Tags = ['category'])&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name       type  dask_compatible  spark_compatible  \\\n",
       "65              haversine  transform            False             False   \n",
       "66          diff_datetime  transform            False             False   \n",
       "67                   year  transform             True              True   \n",
       "68          expanding_min  transform            False             False   \n",
       "69                   hour  transform             True              True   \n",
       "70                    lag  transform            False             False   \n",
       "71          is_year_start  transform             True              True   \n",
       "72  two_digit_postal_code  transform             True              True   \n",
       "73                     or  transform             True              True   \n",
       "74        url_to_protocol  transform            False             False   \n",
       "\n",
       "                                                                                    description  \\\n",
       "65                   Calculates the approximate haversine distance between two LatLong columns.   \n",
       "66  Computes the timedelta between a datetime in a list and the previous datetime in that list.   \n",
       "67                                                     Determines the year value of a datetime.   \n",
       "68                                Computes the expanding minimum of events over a given window.   \n",
       "69                                                     Determines the hour value of a datetime.   \n",
       "70                                  Shifts an array of values by a specified number of periods.   \n",
       "71                                           Determines if a date falls on the start of a year.   \n",
       "72                                         Returns the two digit prefix of a given postal code.   \n",
       "73                                               Performs element-wise logical OR of two lists.   \n",
       "74                                            Determines the protocol (http or https) of a url.   \n",
       "\n",
       "                                                                                           valid_inputs  \\\n",
       "65                                                              <ColumnSchema (Logical Type = LatLong)>   \n",
       "66                                                             <ColumnSchema (Logical Type = Datetime)>   \n",
       "67                                                             <ColumnSchema (Logical Type = Datetime)>   \n",
       "68  <ColumnSchema (Logical Type = Datetime) (Semantic Tags = ['time_index'])>, <ColumnSchema (Semant...   \n",
       "69                                                             <ColumnSchema (Logical Type = Datetime)>   \n",
       "70  <ColumnSchema (Logical Type = Boolean)>, <ColumnSchema (Semantic Tags = ['time_index'])>, <Colum...   \n",
       "71                                                             <ColumnSchema (Logical Type = Datetime)>   \n",
       "72                                                           <ColumnSchema (Logical Type = PostalCode)>   \n",
       "73             <ColumnSchema (Logical Type = Boolean)>, <ColumnSchema (Logical Type = BooleanNullable)>   \n",
       "74                                                                  <ColumnSchema (Logical Type = URL)>   \n",
       "\n",
       "                                                                                            return_type  \n",
       "65                                                         <ColumnSchema (Semantic Tags = ['numeric'])>  \n",
       "66                                                            <ColumnSchema (Logical Type = Timedelta)>  \n",
       "67  <ColumnSchema (Logical Type = Ordinal: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1...  \n",
       "68                                                         <ColumnSchema (Semantic Tags = ['numeric'])>  \n",
       "69  <ColumnSchema (Logical Type = Ordinal: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16...  \n",
       "70                                                                                                 None  \n",
       "71                                                      <ColumnSchema (Logical Type = BooleanNullable)>  \n",
       "72                           <ColumnSchema (Logical Type = Categorical) (Semantic Tags = ['category'])>  \n",
       "73                                                      <ColumnSchema (Logical Type = BooleanNullable)>  \n",
       "74                           <ColumnSchema (Logical Type = Categorical) (Semantic Tags = ['category'])>  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primitives[primitives['type'] == 'transform'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Feature Synthesis\n",
    "\n",
    "[Deep Feature Synthesis (DFS)](https://docs.featuretools.com/en/stable/automated_feature_engineering/afe.html) is the method Featuretools uses to make new features. DFS stacks feature primitives to form features with a \"depth\" equal to the number of primitives. For example, if we take the maximum value of a client's previous loans (say `MAX(previous.loan_amount)`), that is a \"deep feature\" with a depth of 1. To create a feature with a depth of two, we could stack primitives by taking the maximum value of a client's average monthly payments per previous loan (such as `MAX(previous(MEAN(installments.payment)))`). In manual feature engineering, this would require two separate groupings and aggregations and took more than 15 minutes to write the code per feature. \n",
    "\n",
    "Deep Feature Synthesis is an extremely powerful method that allows us to overcome our human limitations on time and creativity by building features that we would never be able to think of on our own (or would not have the patience to implement). Furthermore, DFS is applicable to any dataset with only very minor changes in syntax. In feature engineering, we generally apply the same functions to multiple datasets, but when we do it by hand, we have to re-write the code because it is problem-specific. Featuretools code can be applied to any dataset because it is written at a higher level of abstraction.\n",
    "\n",
    "The [original paper on automated feature engineering using Deep Feature Synthesis](https://dai.lids.mit.edu/wp-content/uploads/2017/10/DSAA_DSM_2015.pdf) is worth a read if you want to understand the concepts at a deeper level.\n",
    "\n",
    "To perform DFS in featuretools, we use the `dfs`  function passing it an `entityset`, the `target_entity` (where we want to make the features), the `agg_primitives` to use, the `trans_primitives` to use, the `max_depth` of the features, and a number of other arguments depending on our use case. There are also options for multi-processing with `njobs` and the information that is printed out with `verbose`. \n",
    "\n",
    "One other important argument is __`features_only`__. If we set this to `True`, `dfs` will only make the feature names and not calculate the actual values of the features (called the feature matrix). This is useful when we want to inspect the feature that will be created and we can also save the features to use with a different dataset (for example when we have training and testing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis with Default Primitives\n",
    "\n",
    "Without using any domain knowledge we can make thousands of features by using the default primitives in featuretools. This first call will use the default aggregation and transformation primitives,  a max depth of 2, and calculate primitives for the `app` entity. We will only generate the features themselves (the names and not the values) which we can save and inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 2097 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/synthesis/dfs.py:321: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:\n",
      "  trans_primitives: ['day', 'haversine', 'month', 'num_characters', 'num_words', 'weekday', 'year']\n",
      "This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible columns for the primitive were found in the data. If the DFS call contained multiple instances of a primitive in the list above, none of them were used.\n",
      "  warnings.warn(warning_msg, UnusedPrimitiveWarning)\n"
     ]
    }
   ],
   "source": [
    "# Default primitives from featuretools\n",
    "default_agg_primitives =  [\"sum\", \"std\", \"max\", \"skew\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "default_trans_primitives =  [\"day\", \"year\", \"month\", \"weekday\", \"haversine\", \"num_words\", \"num_characters\"]\n",
    "\n",
    "# DFS with specified primitives\n",
    "feature_names = ft.dfs(entityset = es, target_dataframe_name = 'app',\n",
    "                       trans_primitives = default_trans_primitives,\n",
    "                       agg_primitives=default_agg_primitives, \n",
    "                       where_primitives = [], seed_features = [],\n",
    "                       max_depth = 2, n_jobs = -1, verbose = 1,\n",
    "                       features_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even a basic call to deep feature synthesis gives us over 2000 features to work with. Granted, not all of these will be important, but this still represents hundreds of hours that we saved. Moreover, `dfs` might be able to find important features that we would never have thought of in the first place. \n",
    "\n",
    "We can look at the some of the feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: MEAN(previous.SUM(credit.AMT_DRAWINGS_POS_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.AMT_INST_MIN_REGULARITY))>,\n",
       " <Feature: MEAN(previous.SUM(credit.AMT_PAYMENT_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.AMT_PAYMENT_TOTAL_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.AMT_RECEIVABLE_PRINCIPAL))>,\n",
       " <Feature: MEAN(previous.SUM(credit.AMT_RECIVABLE))>,\n",
       " <Feature: MEAN(previous.SUM(credit.AMT_TOTAL_RECEIVABLE))>,\n",
       " <Feature: MEAN(previous.SUM(credit.CNT_DRAWINGS_ATM_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.CNT_DRAWINGS_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.CNT_DRAWINGS_OTHER_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.CNT_DRAWINGS_POS_CURRENT))>,\n",
       " <Feature: MEAN(previous.SUM(credit.CNT_INSTALMENT_MATURE_CUM))>,\n",
       " <Feature: MEAN(previous.SUM(credit.MONTHS_BALANCE))>,\n",
       " <Feature: MEAN(previous.SUM(credit.SK_DPD))>,\n",
       " <Feature: MEAN(previous.SUM(credit.SK_DPD_DEF))>,\n",
       " <Feature: MEAN(previous.SUM(installments.AMT_INSTALMENT))>,\n",
       " <Feature: MEAN(previous.SUM(installments.AMT_PAYMENT))>,\n",
       " <Feature: MEAN(previous.SUM(installments.DAYS_ENTRY_PAYMENT))>,\n",
       " <Feature: MEAN(previous.SUM(installments.DAYS_INSTALMENT))>,\n",
       " <Feature: MEAN(previous.SUM(installments.NUM_INSTALMENT_NUMBER))>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[1000:1020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how featuretools stacks multiple primitives on top of each other. This one of the ideas behind Deep Feature Synthesis and automated feature engineering. Rather than having to do these groupings and aggregations by ourselves, Featuretools is able to handle it all using the framework (`entities`, `relationships`, and `primitives`) that we provide. We can also use Featuretools to expand on our domain knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building on Top of Domain Features\n",
    "\n",
    "Featuretools will automatically build thousands of features for us, but that does not mean we can't use our own knowledge to improve the predictive performance. Featuretools is able to augment our domain knowledge by stacking additional features on top of our domain knowledge based features. We identified and created numerous useful features in the manual feature engineering notebook, based on our own knowledge and that of thousands of data scientists working on this problem on Kaggle. Rather than getting only one domain knowledge feature, we can effectively get dozens or even hundreds. __Here we'll explain the options for using domain knowledge, but we'll stick with the simple implementation of Featuretools for comparison purposes.__\n",
    "\n",
    "For more information on any of these topics, see the [documentation](https://docs.featuretools.com/en/stable/guides/tuning_dfs.html) or the other notebooks in this repository. \n",
    "\n",
    "### Seed Features \n",
    "\n",
    "Seed features are domain features that we make in the data that Featuretools is then able to build on top of. For example, we saw that the rate of a loan is an important feature because a higher rate loan is likely more risky. In Featuretools, we can encode the loan rate (both for the current loan and for previous loans) as a seed feature and Featuretools will build additional explanatory variables on this domain knowledge wherever possible. \n",
    "\n",
    "### Interesting Values\n",
    "\n",
    "Interesting values have a similar idea to seed features except they allow us to make conditional features. For example, we might want to find for each client the mean amount of previous loans that have been closed and the mean amount of previous loans that are still active. By specifying interesting values in `bureau` on the `CREDIT_ACTIVE` variable we can have Featuretools do exactly that! Carrying this out by hand would be extremely tedious and present numerous opportunities for errors.\n",
    "\n",
    "### Custom Primitives\n",
    "\n",
    "If we aren't satisfied with the primitives available to use in Featuretools, we can write our own functions to transform or aggregate the data. This is one of the most powerful capabilities in featuretools because it allows us to make very specific operations that can then be applied to multiple datasets. \n",
    "\n",
    "__In this notebook we concentrate on a basic implementation of Featuretools, but keep in mind these capabilities are available for optimizing the library and using domain knowledge!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Primitives\n",
    "\n",
    "For our actual set of features, we will use a select group of primitives rather than just the defaults. This will generate over 2100 features to use for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify primitives\n",
    "agg_primitives =  [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "trans_primitives = ['percentile', 'and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1755 features\n"
     ]
    }
   ],
   "source": [
    "# Deep feature synthesis \n",
    "feature_names = ft.dfs(entityset=es, target_dataframe_name='app',\n",
    "                       agg_primitives = agg_primitives,\n",
    "                       trans_primitives = trans_primitives,\n",
    "                       n_jobs = -1, verbose = 1,\n",
    "                       features_only = True,\n",
    "                       max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_names, 'input/features.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we save the features, we can then use them with `calculate_feature_matrix`. This is useful when we want to apply the same features across datasets (such as if we have separate trainig/testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Full Deep Feature Synthesis\n",
    "\n",
    "If we are content with the features that will be built, we can run deep feature synthesis and create the feature matrix. The following call runs the full deep feature synthesis. This might take a long time depending on your machine. Featuretools does allow for parallel processing, but each core must be able to handle the entire entityset. \n",
    "\n",
    "__An actual run of this code was completed using Dask which can be seen in the [Featuretools on Dask notebook](https://github.com/Featuretools/Automated-Manual-Comparison/blob/master/Loan%20Repayment/notebooks/Featuretools%20on%20Dask.ipynb).__ The Dask code takes under 2 hours to run and is a great example of how we can use parallel processing to use our resouces in the most efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of entityset: 4.15296 gb.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Total size of entityset: {:.5f} gb.'.format(sys.getsizeof(es) / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cpus detected: 12.\n",
      "Total size of system memory: 24.92599 gb.\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "print('Total number of cpus detected: {}.'.format(psutil.cpu_count()))\n",
    "print('Total size of system memory: {:.5f} gb.'.format(psutil.virtual_memory().total / 1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 392 features\n",
      "Elapsed: 00:00 | Progress:   0%|          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:02 | Progress:  56%|█████▌    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function mean at 0x7fa24090ee60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  ).agg(to_agg)\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function amin at 0x7fa24090e440> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  ).agg(to_agg)\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function amax at 0x7fa24090e290> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  ).agg(to_agg)\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function sum at 0x7fa24090da20> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ).agg(to_agg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 01:48 | Progress:  72%|███████▏  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function mean at 0x7fa24090ee60> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  ).agg(to_agg)\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function amin at 0x7fa24090e440> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  ).agg(to_agg)\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function amax at 0x7fa24090e290> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  ).agg(to_agg)\n",
      "/home/minhduck/Documents/projects/vnstock/venv/lib/python3.10/site-packages/featuretools/computational_backends/feature_set_calculator.py:829: FutureWarning: The provided callable <function sum at 0x7fa24090da20> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ).agg(to_agg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 13:23 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, target_dataframe_name='app',\n",
    "                                       agg_primitives = agg_primitives,\n",
    "                                       trans_primitives = trans_primitives,\n",
    "                                       n_jobs = 1, verbose = 1, features_only = False,\n",
    "                                       max_depth = 1, chunk_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 122)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(app), len(app.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(list(feature_matrix.columns) == feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in app.columns if f not in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.list_primitives().to_csv('ft_primitives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>PERCENTILE(REG_REGION_NOT_LIVE_REGION)</th>\n",
       "      <th>PERCENTILE(REG_REGION_NOT_WORK_REGION)</th>\n",
       "      <th>PERCENTILE(TARGET)</th>\n",
       "      <th>PERCENTILE(TOTALAREA_MODE)</th>\n",
       "      <th>PERCENTILE(YEARS_BEGINEXPLUATATION_AVG)</th>\n",
       "      <th>PERCENTILE(YEARS_BEGINEXPLUATATION_MEDI)</th>\n",
       "      <th>PERCENTILE(YEARS_BEGINEXPLUATATION_MODE)</th>\n",
       "      <th>PERCENTILE(YEARS_BUILD_AVG)</th>\n",
       "      <th>PERCENTILE(YEARS_BUILD_MEDI)</th>\n",
       "      <th>PERCENTILE(YEARS_BUILD_MODE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>0.116199</td>\n",
       "      <td>0.094693</td>\n",
       "      <td>0.094483</td>\n",
       "      <td>0.099797</td>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.076174</td>\n",
       "      <td>0.079709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>0.523410</td>\n",
       "      <td>0.662232</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.671567</td>\n",
       "      <td>0.650664</td>\n",
       "      <td>0.650468</td>\n",
       "      <td>0.658963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100006</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.396748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456221</th>\n",
       "      <td>456221</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>412560.0</td>\n",
       "      <td>17473.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456222</th>\n",
       "      <td>456222</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>622413.0</td>\n",
       "      <td>31909.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456223</th>\n",
       "      <td>456223</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>33205.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>0.814255</td>\n",
       "      <td>0.947184</td>\n",
       "      <td>0.945396</td>\n",
       "      <td>0.946513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456224</th>\n",
       "      <td>456224</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>25128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.974316</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>0.864738</td>\n",
       "      <td>0.868677</td>\n",
       "      <td>0.868255</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456250</th>\n",
       "      <td>456250</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>24709.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492177</td>\n",
       "      <td>0.474316</td>\n",
       "      <td>0.896748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356255 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "100002      100002       1         Cash loans           M         False   \n",
       "100003      100003       0         Cash loans           F         False   \n",
       "100004      100004       0    Revolving loans           M          True   \n",
       "100006      100006       0         Cash loans           F         False   \n",
       "100007      100007       0         Cash loans           M         False   \n",
       "...            ...     ...                ...         ...           ...   \n",
       "456221      456221    <NA>         Cash loans           F         False   \n",
       "456222      456222    <NA>         Cash loans           F         False   \n",
       "456223      456223    <NA>         Cash loans           F          True   \n",
       "456224      456224    <NA>         Cash loans           M         False   \n",
       "456250      456250    <NA>         Cash loans           F          True   \n",
       "\n",
       "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "100002             True             0          202500.0    406597.5   \n",
       "100003            False             0          270000.0   1293502.5   \n",
       "100004             True             0           67500.0    135000.0   \n",
       "100006             True             0          135000.0    312682.5   \n",
       "100007             True             0          121500.0    513000.0   \n",
       "...                 ...           ...               ...         ...   \n",
       "456221             True             0          121500.0    412560.0   \n",
       "456222            False             2          157500.0    622413.0   \n",
       "456223             True             1          202500.0    315000.0   \n",
       "456224            False             0          225000.0    450000.0   \n",
       "456250            False             0          135000.0    312768.0   \n",
       "\n",
       "        AMT_ANNUITY  ...  PERCENTILE(REG_REGION_NOT_LIVE_REGION)  \\\n",
       "100002      24700.5  ...                                0.492177   \n",
       "100003      35698.5  ...                                0.492177   \n",
       "100004       6750.0  ...                                0.492177   \n",
       "100006      29686.5  ...                                0.492177   \n",
       "100007      21865.5  ...                                0.492177   \n",
       "...             ...  ...                                     ...   \n",
       "456221      17473.5  ...                                0.492177   \n",
       "456222      31909.5  ...                                0.492177   \n",
       "456223      33205.5  ...                                0.492177   \n",
       "456224      25128.0  ...                                0.492177   \n",
       "456250      24709.5  ...                                0.492177   \n",
       "\n",
       "       PERCENTILE(REG_REGION_NOT_WORK_REGION) PERCENTILE(TARGET)  \\\n",
       "100002                               0.474316           0.896748   \n",
       "100003                               0.474316           0.396748   \n",
       "100004                               0.474316           0.396748   \n",
       "100006                               0.474316           0.396748   \n",
       "100007                               0.474316           0.396748   \n",
       "...                                       ...                ...   \n",
       "456221                               0.474316           0.896748   \n",
       "456222                               0.474316           0.896748   \n",
       "456223                               0.474316           0.896748   \n",
       "456224                               0.974316           0.896748   \n",
       "456250                               0.474316           0.896748   \n",
       "\n",
       "       PERCENTILE(TOTALAREA_MODE) PERCENTILE(YEARS_BEGINEXPLUATATION_AVG)  \\\n",
       "100002                   0.116199                                0.094693   \n",
       "100003                   0.523410                                0.662232   \n",
       "100004                        NaN                                     NaN   \n",
       "100006                        NaN                                     NaN   \n",
       "100007                        NaN                                     NaN   \n",
       "...                           ...                                     ...   \n",
       "456221                        NaN                                     NaN   \n",
       "456222                        NaN                                     NaN   \n",
       "456223                   0.814255                                0.947184   \n",
       "456224                   0.864738                                0.868677   \n",
       "456250                        NaN                                     NaN   \n",
       "\n",
       "       PERCENTILE(YEARS_BEGINEXPLUATATION_MEDI)  \\\n",
       "100002                                 0.094483   \n",
       "100003                                 0.661834   \n",
       "100004                                      NaN   \n",
       "100006                                      NaN   \n",
       "100007                                      NaN   \n",
       "...                                         ...   \n",
       "456221                                      NaN   \n",
       "456222                                      NaN   \n",
       "456223                                 0.945396   \n",
       "456224                                 0.868255   \n",
       "456250                                      NaN   \n",
       "\n",
       "        PERCENTILE(YEARS_BEGINEXPLUATATION_MODE)  PERCENTILE(YEARS_BUILD_AVG)  \\\n",
       "100002                                  0.099797                     0.076274   \n",
       "100003                                  0.671567                     0.650664   \n",
       "100004                                       NaN                          NaN   \n",
       "100006                                       NaN                          NaN   \n",
       "100007                                       NaN                          NaN   \n",
       "...                                          ...                          ...   \n",
       "456221                                       NaN                          NaN   \n",
       "456222                                       NaN                          NaN   \n",
       "456223                                  0.946513                          NaN   \n",
       "456224                                  0.874847                          NaN   \n",
       "456250                                       NaN                          NaN   \n",
       "\n",
       "        PERCENTILE(YEARS_BUILD_MEDI)  PERCENTILE(YEARS_BUILD_MODE)  \n",
       "100002                      0.076174                      0.079709  \n",
       "100003                      0.650468                      0.658963  \n",
       "100004                           NaN                           NaN  \n",
       "100006                           NaN                           NaN  \n",
       "100007                           NaN                           NaN  \n",
       "...                              ...                           ...  \n",
       "456221                           NaN                           NaN  \n",
       "456222                           NaN                           NaN  \n",
       "456223                           NaN                           NaN  \n",
       "456224                           NaN                           NaN  \n",
       "456250                           NaN                           NaN  \n",
       "\n",
       "[356255 rows x 514 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([app.copy(), feature_matrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_matrix.reset_index(inplace = True)\n",
    "# feature_matrix.to_csv('../input/feature_matrix.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the feature matrix, head to https://www.kaggle.com/willkoehrsen/home-credit-default-risk-feature-tools and select the `feature_matrix_article.csv`. There are several other versions of automatically engineered feature matrices available there as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we saw how to implement automated feature engineering for a data science problem. __Automated feature engineering allows us to create thousands of new features from a set of related data tables, significantly increasing our efficiency as data scientists.__ Moreover, we can still use domain knowledge in our features and even augment our domain knowledge by building on top of our own hand-built features. The main takeaways are:\n",
    "\n",
    "* Automated feature engineering took 1 hour to implement compared to 10 hours for manual feature engineering\n",
    "* Automated feature engineering built thousands of features in a few lines of code compared to dozens of lines of code per feature for manual engineering.\n",
    "* Overall, performance of the automated features are comparable or better than those of the manual features (see the Results notebook)\n",
    "\n",
    "The benefits of automated feature engineering are significant and will considerably help us in our role as data scientists. It won't alleviate the need for data scientists, but rather will make us more efficient and build better predictive pipelines in less time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After creating a full set of features, we can apply feature selection and then proceed with modeling. To optimize the model for the features, we use random search for 100 iterations over a grid of hyperparamters. To see how to use Dask to run Featuretools in parallel, refer to the Featuretools Implementation with Dask notebook. For feature selection refer to the Feature Selection notebook. Final results are presented in the Results notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <img src=\"https://www.featurelabs.com/wp-content/uploads/2017/12/logo.png\" alt=\"Featuretools\" />\n",
    "</p>\n",
    "\n",
    "Featuretools was created by the developers at [Feature Labs](https://www.featurelabs.com/). If building impactful data science pipelines is important to you or your business, please [get in touch](https://www.featurelabs.com/contact)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
